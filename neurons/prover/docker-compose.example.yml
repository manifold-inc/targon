version: '3.8'

services:
  text-generation-service:
    image: ghcr.io/huggingface/text-generation-inference:1.3
    command: --model-id mlabonne/NeuralDaredevil-7B --max-input-length 3072 --max-total-tokens 4096
    volumes:
      - ./models:/data
    ports:
      - "127.0.0.1:8080:80"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu]
    shm_size: '1g'
  #prover:
  #  build:
  #    context: .
  #    dockerfile: Dockerfile
  #  ports:
  #    - "8091:8091"
  #  command: ./entrypoint.sh
  #  volumes:
  #    - ~/.bittensor/wallets:/root/.bittensor/wallets

  # common: &common
  #   image: opentensor/subtensor:latest
  #   build:
  #     context: .
  #     dockerfile: Dockerfile
  #     target: subtensor
  #   cpu_count: 4
  #   mem_limit: 40000000000
  #   memswap_limit: 80000000000
  #   ports:
  #     - "9944:9944"
  #     - "30333:30333"
  #     - "9933:9933"
  #   expose:
  #     - "9944"
  #     - "30333"
  #     - "9933"
  #   environment:
  #     - CARGO_HOME=/var/www/node-subtensor/.cargo

  # mainnet-lite:
  #   <<: *common
  #   container_name: subtensor-mainnet-lite
  #   volumes:
  #     - mainnet-lite-volume:/tmp/blockchain
  #   command:
  #     - /bin/bash
  #     - -c
  #     - |
  #       node-subtensor \
  #         --base-path /tmp/blockchain \
  #         --chain raw_spec.json \
  #         --rpc-external --rpc-cors all \
  #         --ws-external --no-mdns \
  #         --ws-max-connections 10000 --in-peers 500 --out-peers 500 \
  #         --bootnodes /dns/bootnode.finney.opentensor.ai/tcp/30333/ws/p2p/12D3KooWRwbMb85RWnT8DSXSYMWQtuDwh4LJzndoRrTDotTR5gDC \
  #         --sync warp




volumes:
  db:
    driver: local
  mainnet-lite-volume:
